{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a notebook for producing inversion ready AEM data files (for use with Ross C brodie's inversion codes) from a netCDF4 data and recalculated noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4\n",
    "import numpy as np\n",
    "import os\n",
    "from sqlite3 import dbapi2 as sqlite\n",
    "import sqlalchemy as db\n",
    "from sqlalchemy import create_engine, event\n",
    "from geophys_utils import NetCDFPointUtils\n",
    "from hydrogeol_utils import spatial_functions\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the AEM data file\n",
    "nc_inpath = r\"C:\\Users\\PCUser\\Desktop\\2017_HowardsEast_SkyTEM\\01_EM\\AUS_10021_HowardE_EM.nc\"\n",
    "\n",
    "d = netCDF4.Dataset(nc_inpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "742832.5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(d['easting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to load a number of coordiantes that we will be inverting the nearest neighbour\n",
    "\n",
    "# Extract borehole data from the database\n",
    "\n",
    "DB_PATH = r\"C:\\Users\\PCUser\\Desktop\\EK_data\\Boreholes\\East_Kimberley_borehole_data.sqlite\"\n",
    "\n",
    "engine = db.create_engine('sqlite:///' + DB_PATH, module=sqlite)\n",
    "\n",
    "connection = engine.connect()\n",
    "\n",
    "# Open the borehole data as a pandas dataframe\n",
    "\n",
    "df_header =pd.read_sql('select Easting, Northing from borehole', connection)\n",
    "\n",
    "# Now do the same for SNMR sites\n",
    "\n",
    "DB_PATH = r\"C:\\Users\\PCUser\\Desktop\\EK_data\\SNMR\\East_Kimberley_SNMR.sqlite\"\n",
    "\n",
    "engine = db.create_engine('sqlite:///' + DB_PATH, module=sqlite)\n",
    "\n",
    "connection = engine.connect()\n",
    "\n",
    "# Open the borehole data as a pandas dataframe\n",
    "\n",
    "df_SNMR =pd.read_sql('select mid_X, mid_Y from sites', connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get coordinates in an array\n",
    "\n",
    "coords = np.zeros(shape = (len(df_header) + len(df_SNMR), 2),\n",
    "                 dtype = np.float64)\n",
    "\n",
    "coords[:len(df_header),:] = df_header.values\n",
    "\n",
    "coords[len(df_header):,:] = df_SNMR.values\n",
    "\n",
    "df_coords = pd.DataFrame(coords, columns = ['Easting', 'Northing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_point_utils = NetCDFPointUtils(d)\n",
    "\n",
    "# Get the AEM utm coordinates\n",
    "\n",
    "aem_coords = np.column_stack((d['easting'][:], d['northing']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the AEM conductivity using nearest neighbour\n",
    "distances, indices = spatial_functions.nearest_neighbours(coords,\n",
    "                                                          aem_coords,\n",
    "                                                          points_required = 1,# return 10 closest points\n",
    "                                                          max_distance = 250.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_inds = np.unique(indices[np.isfinite(distances)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = d['line'][:].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([100101, 100201, 100301, 100401, 100501, 100601, 100701, 100702,\n",
       "       100801, 100802, 100901, 100902, 101001, 101003, 101101, 101102,\n",
       "       101201, 101202, 101301, 101302, 101401, 101402, 101501, 101502,\n",
       "       101601, 101602, 101604, 101701, 101702, 101801, 101803, 101901,\n",
       "       101903, 102001, 102003, 102101, 102103, 102201, 102203, 102301,\n",
       "       102303, 102401, 102402, 102404, 102501, 102502, 102504, 102601,\n",
       "       102602, 102701, 102702, 102801, 102802, 102901, 102902, 103001,\n",
       "       103002, 103101, 103103, 103201, 103202, 103301, 103302, 103304,\n",
       "       103401, 103551, 103601, 103701, 103801, 103901, 104001, 104101,\n",
       "       104201, 104301, 104401, 104501, 104601, 104701, 104801, 104901,\n",
       "       105001, 105101, 105201, 105301, 105401, 105501, 105601, 105701,\n",
       "       105801, 105901, 106001, 106101, 106201, 106301, 106401, 106501,\n",
       "       106601, 106701, 106801, 106901, 107001, 107101, 107201, 107301,\n",
       "       107401, 107501, 107601, 107701, 107801, 107901, 108001, 108101,\n",
       "       108201, 108301, 108401, 108501, 108601, 108701, 108801, 108901,\n",
       "       109001, 109101, 109201, 109301, 109401, 109501, 109601, 109701,\n",
       "       109801, 109901, 110001, 110101, 110201, 110301, 110401, 110501,\n",
       "       110502, 110601, 110701, 110801, 110901, 111001, 111002, 111101,\n",
       "       111201, 111301, 111401, 111501, 111601, 111701, 111801, 111901,\n",
       "       112001, 112101, 112201, 112301, 112401, 112501, 112601, 112701,\n",
       "       112801, 112901, 113001, 113101, 113201, 113301, 113401, 113501,\n",
       "       113601, 113701, 113801, 113901, 114001, 114101, 114201, 114301,\n",
       "       114401, 114501, 114601, 114701, 114801, 114901, 115001, 115101,\n",
       "       115201, 115301, 115401, 115451, 115501, 115551, 115601, 115651,\n",
       "       115701, 115751, 115801, 115851, 115901, 115951, 116001, 116051,\n",
       "       116101, 116151, 116201, 116251, 116301, 116351, 116401, 116451,\n",
       "       116501, 116551, 116601, 116651, 116701, 116801, 116901, 117001,\n",
       "       117101, 117201, 117301, 117401, 117501, 117601, 117701, 117801,\n",
       "       117901, 118001, 118101, 200101, 200201, 200301, 200401, 200501,\n",
       "       200601, 200701, 200801, 912001, 912002, 912003, 912004, 912005,\n",
       "       912006, 912007, 912008, 912009, 912010, 912011, 912012, 912013,\n",
       "       912014, 912015, 912016, 912017, 912018, 913001, 913002, 913003,\n",
       "       913004, 913005, 913006, 913007, 913008, 913009, 913010, 913011,\n",
       "       913012, 913013, 913014, 913015, 913016, 913017, 913018, 913019])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lines' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-37934517e995>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# get a subset of the Keep data from line 300,000-400,000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mKeep_lines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogical_and\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m300000.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;36m400000.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mKeep_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcond_point_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_lookup_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKeep_lines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lines' is not defined"
     ]
    }
   ],
   "source": [
    "# get a subset of the Keep data from line 300,000-400,000\n",
    "\n",
    "Keep_lines = [x for x in lines if np.logical_and(x>100000., x<400000.)]\n",
    "\n",
    "Keep_mask = cond_point_utils.get_lookup_mask(Keep_lines)\n",
    "\n",
    "Keep_inds = np.where(Keep_mask)[0]\n",
    "\n",
    "# Get 10,000 random points\n",
    "\n",
    "#np.random.shuffle(Keep_inds)\n",
    "\n",
    "masked_inds = Keep_inds#[:10000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167007"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['northing'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now for these points we want to extract data into a .dat file with formatting defined by a dfn\n",
    "\n",
    "\n",
    "\n",
    "cols = [\"ga_project\", \"utc_date\", \"flight\", \"line\", \"fiducial\", \"easting\", \"northing\",\n",
    "        \"tx_height_measured\", \"elevation\", \"gps_height\", \"roll\", \"pitch\", \"yaw\",\n",
    "        \"TxRx_dx\", \"TxRx_dy\", \"TxRx_dz\", \"low_moment_Z-component_EM_data\",\"high_moment_Z-component_EM_data\",\n",
    "             \"lm_z_noise\", \"hm_z_noise\"]\n",
    "inv_read = {}\n",
    "\n",
    "for item in cols:\n",
    "    # Scalar variables\n",
    "    if len(d[item].shape) == 0:\n",
    "        inv_read[item] = d[item][:].data\n",
    "    # Vectors\n",
    "    elif len(d[item].shape) == 1:\n",
    "        if item == 'line':\n",
    "            line_inds = d['line_index'][:]#[masked_inds]\n",
    "            inv_read[item] = d[item][line_inds].data\n",
    "        elif item == 'flight':\n",
    "            flight_inds = d['flight_index'][:]#[masked_inds]\n",
    "            inv_read[item] = d[item][flight_inds].data            \n",
    "        else:\n",
    "            inv_read[item] = d[item][:].data#[masked_inds].data\n",
    "    # Arrays\n",
    "    elif len(d[item].shape) == 2:\n",
    "        inv_read[item] = d[item][:].data#[masked_inds].data\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inv_read['lm_z_noise'] = 0.5*inv_read['lm_z_noise']\n",
    "#inv_read['hm_z_noise'] = 0.5*inv_read['hm_z_noise']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(index = range(d['northing'].shape[0]))#masked_inds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in inv_read:\n",
    "    if len(inv_read[item].shape) < 2:\n",
    "        df[item] = inv_read[item]\n",
    "    else:\n",
    "        a = inv_read[item]\n",
    "        for i in range(a.shape[1]):\n",
    "            df[item + '_' + str(i+1)] = a[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any entries with high altitude lines\n",
    "\n",
    "df = df[df['line'] < 913000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to resave these columns as strings with a set format\n",
    "\n",
    "# Now we replace the columns with formatted strings\n",
    "\n",
    "df.at[:,'ga_project'] = ['{:5d}'.format(x) for x in df['ga_project'].values.astype(int)]\n",
    "df.at[:,'utc_date'] = ['{:9.0F}'.format(x) for x in df['utc_date'].values]\n",
    "df.at[:,'flight'] = ['{:12.2F}'.format(x) for x in df['flight'].values]\n",
    "df.at[:,'line'] = ['{:8.0F}'.format(x) for x in df['line'].values]\n",
    "df.at[:,'fiducial'] = ['{:12.2F}'.format(x) for x in df['fiducial'].values]\n",
    "df.at[:,'easting'] = ['{:10.2F}'.format(x) for x in df['easting'].values]\n",
    "df.at[:,'northing'] = ['{:11.2F}'.format(x) for x in df['northing'].values]\n",
    "df.at[:,'tx_height_measured'] = ['{:8.1F}'.format(x) for x in df['tx_height_measured'].values]\n",
    "df.at[:,'elevation'] = ['{:9.2F}'.format(x) for x in df['elevation'].values]\n",
    "df.at[:,'gps_height'] = ['{:9.2F}'.format(x) for x in df['gps_height'].values]\n",
    "df.at[:,'roll'] = ['{:7.2F}'.format(x) for x in df['roll'].values]\n",
    "df.at[:,'pitch'] = ['{:7.2F}'.format(x) for x in df['pitch'].values]\n",
    "df.at[:,'yaw'] = ['{:7.2F}'.format(x) for x in df['yaw'].values]\n",
    "df.at[:,'TxRx_dx'] = ['{:7.2F}'.format(x) for x in df['TxRx_dx'].values]\n",
    "df.at[:,'TxRx_dy'] = ['{:7.2F}'.format(x) for x in df['TxRx_dy'].values]\n",
    "df.at[:,'TxRx_dz'] = ['{:7.2F}'.format(x) for x in df['TxRx_dz'].values]\n",
    "\n",
    "\n",
    "# Iterate through the the data\n",
    "\n",
    "for item in df.columns[16:]:\n",
    "    df.at[:,item] = ['{:15.6E}'.format(x) for x in df[item].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we output the data\n",
    "outfile = r\"C:\\Users\\PCUser\\Desktop\\2017_HowardsEast_SkyTEM\\01_EM\\inversion_ready\\HE_temp.dat\"\n",
    "\n",
    "# Note use a pipe so we can easily delete later\n",
    "df.to_csv(outfile, sep = '|', index = False, header = False)\n",
    "\n",
    "# Now opent the file and delete the pipe\n",
    "\n",
    "with open(outfile, 'r') as inf:\n",
    "    s = inf.read()\n",
    "\n",
    "new_s = s.replace('|','')\n",
    "\n",
    "\n",
    "# Reomve the final\n",
    "if new_s[-1:] == '\\n':\n",
    "    new_s = new_s[:-1]\n",
    "\n",
    "new_outfile = r\"C:\\Users\\PCUser\\Desktop\\2017_HowardsEast_SkyTEM\\01_EM\\inversion_ready\\HE_inversion_read.dat\"\n",
    "\n",
    "with open(new_outfile, 'w') as f:\n",
    "    f.write(new_s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we output the data\n",
    "outfile = r\"C:\\Users\\PCUser\\Desktop\\EK_data\\AEM\\inversion_ready_data\\OrdKeep_inversion_ready_subset_temp.dat\"\n",
    "\n",
    "# Note use a pipe so we can easily delete later\n",
    "df.iloc[0].to_csv(outfile, sep = '|', index = False, header = False)\n",
    "\n",
    "# Now opent the file and delete the pipe\n",
    "\n",
    "with open(outfile, 'r') as inf:\n",
    "    s = inf.read()\n",
    "\n",
    "new_s = s.replace('|','')\n",
    "\n",
    "\n",
    "# Reomve the final\n",
    "if new_s[-1:] == '\\n':\n",
    "    new_s = new_s[:-1]\n",
    "\n",
    "new_outfile = r\"C:\\Users\\PCUser\\Desktop\\EK_data\\AEM\\inversion_ready_data\\OrdKeep_inversion_ready_onefid.dat\"\n",
    "\n",
    "with open(new_outfile, 'w') as f:\n",
    "    f.write(new_s)\n"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
