{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import aseg_gdf2\n",
    "from shapely.geometry import Point, LineString, MultiPoint, Polygon\n",
    "from shapely.wkt import loads\n",
    "from scipy.io import loadmat\n",
    "from scipy import spatial\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "import netCDF4\n",
    "import h5py\n",
    "import gc\n",
    "import os\n",
    "import glob\n",
    "from scipy.spatial.ckdtree import cKDTree\n",
    "from hydrogeol_utils import SNMR_utils, spatial_functions, AEM_utils\n",
    "from hydrogeol_utils import plotting_utils as plot_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_neighbours(points, coords, points_required = 1, max_distance = 250.):\n",
    "    \"\"\"\n",
    "\n",
    "    :param points: array of points to find the nearest neighbour for\n",
    "    :param coords: coordinates of points\n",
    "    :param points_required: number of points to return\n",
    "    :param max_distance: maximum search radius\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Initialise tree instance\n",
    "    kdtree = cKDTree(data=coords)\n",
    "\n",
    "    # iterate throught the points and find the nearest neighbour\n",
    "    distances, indices = kdtree.query(points, k=points_required,\n",
    "                                      distance_upper_bound=max_distance)\n",
    "    print(distances)\n",
    "    # Mask out infitnite distances in indices to avoid confusion\n",
    "    mask = ~np.isfinite(distances)\n",
    "\n",
    "    distances[mask] = np.nan\n",
    "\n",
    "    return distances, indices\n",
    "\n",
    "# Find the nearest neighbours within the maximum distance\n",
    "\n",
    "def xy_2_var(grid_dict, xy, var):\n",
    "    \"\"\"\n",
    "    Function for finding a variable for gridded AEM sections\n",
    "    given an input easting and northing\n",
    "    @ param: grid_dict :dictionary for gridded line data\n",
    "    @ param: xy: numpy array with easting and northing\n",
    "    @ param: var: string with variable name\n",
    "    returns\n",
    "    float: distance along line\n",
    "    \"\"\"\n",
    "    utm_coords = np.column_stack((grid_dict['easting'],\n",
    "                                  grid_dict['northing']))\n",
    "\n",
    "    d, i = spatial_functions.nearest_neighbours(xy,\n",
    "                                                utm_coords,\n",
    "                                                points_required=1,\n",
    "                                                max_distance=100.)\n",
    "    if np.isnan(d[0]):\n",
    "        return None\n",
    "\n",
    "    else:\n",
    "        near_ind = i[0]\n",
    "    \n",
    "\n",
    "\n",
    "        return grid_dict[var][near_ind]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = r\"C:\\Users\\PCUser\\Desktop\\AEM\\LCI\\DalyR_WB_MGA52.nc\"\n",
    "\n",
    "lci_dat = netCDF4.Dataset(infile)\n",
    "\n",
    "lci_coords = np.column_stack((lci_dat['easting'][:],\n",
    "                          lci_dat['northing'][:]))\n",
    "\n",
    "# Initialise tree instance for nearest neighbour searches\n",
    "kdtree = cKDTree(data=lci_coords)\n",
    "\n",
    "\n",
    "# bring in the rjmcmc data\n",
    "\n",
    "infile = r\"C:\\Users\\PCUser\\Desktop\\AEM\\rjmcmc\\DalyRiver_rjmcmc.nc\"\n",
    "\n",
    "# Read in the data\n",
    "\n",
    "rj_dat = netCDF4.Dataset(infile)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we will be wanting to plot the sections lets first grid them\n",
    "\n",
    "# Create an instance of plots for gridding the data\n",
    "\n",
    "plots = plot_utils.ConductivitySectionPlot(lci_dat)\n",
    "\n",
    "\n",
    "# Define some key variables which we want to inteprolate\n",
    "\n",
    "cond_vars = ['conductivity', 'data_residual', 'depth_of_investigation']\n",
    "\n",
    "plots.conductivity_variables = cond_vars\n",
    "\n",
    "\n",
    "# Define the resolution of th sections\n",
    "xres, yres = 10., 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the lines from the rj\n",
    "\n",
    "lines = rj_dat['line'][:]\n",
    "\n",
    "# Now grid the lines and save in memory\n",
    "\n",
    "hdf5_dir = r\"C:\\Users\\PCUser\\Desktop\\NSC_data\\data\\AEM\\DR\\lci\\hdf5\"\n",
    "\n",
    "if not os.path.exists(hdf5_dir):\n",
    "    os.mkdir(hdf5_dir)\n",
    "\n",
    "gridded_vars ={}\n",
    "\n",
    "# Saved these out to save time\n",
    "\n",
    "#gridded_vars = plots.grid_variables(xres = xres, yres =yres, lines=lines,\n",
    "#                                    resampling_method = 'cubic', save_hdf5 = True,\n",
    " #                                   return_dict = True, hdf5_dir = hdf5_dir)\n",
    "\n",
    "for line in lines:\n",
    "    \n",
    "    infile = os.path.join(hdf5_dir, str(line) + '.hdf5')\n",
    "    f = h5py.File(infile, 'r')\n",
    "    gridded_vars[line] = plot_utils.extract_hdf5_data(f, cond_vars)\n",
    "    f = None\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we bring in the Oolloo Jinduckin contact to plot\n",
    "\n",
    "#inRaster = r\"C:\\Users\\PCUser\\Desktop\\NSC_data\\data\\raster\\Daly_Aquifers\\export\\topOolloo_BOM.tif\"\n",
    "inRaster = r\"C:\\Users\\PCUser\\Desktop\\NSC_data\\data\\raster\\Daly_Aquifers\\export\\tJind_BOM.tif\"\n",
    "\n",
    "contact_dataset = rasterio.open(inRaster)\n",
    "\n",
    "contact_elev = contact_dataset.read(1)\n",
    "\n",
    "contact_elev[contact_elev == contact_dataset.get_nodatavals()] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to find the top of the Jinduckin for every gridded lci section\n",
    "\n",
    "for line in gridded_vars.keys():\n",
    "    \n",
    "    # Get the coordinates\n",
    "    utm_coords = utm_coords = np.column_stack((gridded_vars[line]['easting'],\n",
    "                                               gridded_vars[line]['northing']))\n",
    "    # sample the raster at the coordinates\n",
    "    \n",
    "    elevGen = contact_dataset.sample(utm_coords)\n",
    "    \n",
    "    gridded_vars[line]['topJind_elev'] = np.nan*np.ones(shape = utm_coords.shape[0],\n",
    "                                                 dtype = np.float)\n",
    "    \n",
    "    for i in range(utm_coords.shape[0]):\n",
    "        \n",
    "        jindElev =  next(elevGen)\n",
    "\n",
    "        if not np.isclose(jindElev,contact_dataset.get_nodatavals()[0]):\n",
    "            gridded_vars[line]['topJind_elev'][i] = jindElev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we bring in the magnetics to plot\n",
    "\n",
    "inRaster = r\"C:\\Users\\PCUser\\Desktop\\NSC_data\\data\\AEM\\DR\\2017_DalyRiver_SkyTEM\\03_LCI\\03_Depth_Slices\\Grids_doi_Masked\\*.ers\"\n",
    "\n",
    "cond = {}\n",
    "\n",
    "for file in glob.glob(inRaster):\n",
    "    layer = int(file.split('Con')[1].split('_')[0])\n",
    "    cond_dataset = rasterio.open(file)\n",
    "    cond[layer] = cond_dataset.read(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring in a subset of the points to sample\n",
    "\n",
    "infile = r\"C:\\Users\\PCUser\\Desktop\\NSC_data\\data\\AEM\\DR\\garjmcmctdem_2\\combined\\rjmcmc_map.csv\"\n",
    "\n",
    "df = pd.read_csv(infile)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator for sampling the bom raster\n",
    "contElev = contact_dataset.sample(df[['easting ', 'northing ']].values)\n",
    "\n",
    "# Add the distance along the gridded lines to the dataframe\n",
    "\n",
    "df['dist_along_line'] = np.nan\n",
    "\n",
    "df['point_ind_rj'] = -9999\n",
    "\n",
    "df['point_ind_lci'] = -9999\n",
    "\n",
    "df['topJind_depth'] = np.nan\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "\n",
    "    # get the line and coordinates\n",
    "    line = row['line ']\n",
    "    \n",
    "    xy = np.array([row[['easting ','northing ']].values])\n",
    "    \n",
    "    df.loc[index,'dist_along_line'] = xy_2_var(gridded_vars[line],\n",
    "                                               xy,'grid_distances')\n",
    "    \n",
    "    df.loc[index,'point_ind_rj'] = np.where(rj_dat['fiducial'][:]== row['fiducial '])[0][0]\n",
    "    \n",
    "    df.loc[index,'point_ind_lci'] = kdtree.query(row[['easting ', 'northing ']].values)[1]\n",
    "    \n",
    "    jindElev = next(contElev)[0]\n",
    "    \n",
    "    if not np.isclose(jindElev,contact_dataset.get_nodatavals()[0]):\n",
    "        \n",
    "        df.loc[index,'topJind_depth'] = row['elevation '] - jindElev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ss = df[df['topJind_depth'] < 400.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PCUser\\Anaconda3\\envs\\hydrogeol_utils\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_ss['topJind_interp'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a generator to iterate through the pandas dataframe\n",
    "\n",
    "def gen(df):\n",
    "    for index, row in df.iterrows():\n",
    "        yield index, row\n",
    "        \n",
    "#cond_gen = gen(df_rj_ss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function stores the top of the conductor in the dataframe on a click\n",
    "def onclick(event):\n",
    "    if event.xdata != None and event.ydata != None:\n",
    "        df_ss.at[ind, 'topJind_interp'] = event.ydata\n",
    "\n",
    "\n",
    "def extract_data():\n",
    "    \"\"\"\n",
    "    FUnction for extracting all the AEM data from the netCDF files\n",
    "    \"\"\"\n",
    "\n",
    "    freq = rj_dat['conductivity_bin_count'][point_ind_rj].data.astype(np.float)\n",
    "\n",
    "    cond_pdf = freq / freq.sum(axis =1)[0]\n",
    "\n",
    "    cond_pdf[cond_pdf == 0] = np.nan\n",
    "    \n",
    "    cp_freq = rj_dat['change_point'][point_ind_rj].data.astype(np.float)\n",
    "    \n",
    "    cp_pdf = cp_freq / freq.sum(axis =1)[0]\n",
    "    \n",
    "    laybins = rj_dat['nlayer_bin_count'][point_ind_rj].data\n",
    "    \n",
    "    lay_prob = laybins / freq.sum(axis =1)[0]\n",
    "    \n",
    "    cond_cells = rj_dat[\"conductivity_cells\"][:].data\n",
    "    \n",
    "    depth_cells = rj_dat['layer_top_depth'][point_ind_rj].data\n",
    "    \n",
    "    extent = [cond_cells.min(), cond_cells.max(), depth_cells.max(), depth_cells.min()]\n",
    "    \n",
    "    mean = rj_dat['conductivity_mean'][point_ind_rj].data\n",
    "    p10 = rj_dat['conductivity_p10'][point_ind_rj].data\n",
    "    p50 = rj_dat['conductivity_p50'][point_ind_rj].data\n",
    "    p90 = rj_dat['conductivity_p90'][point_ind_rj].data\n",
    "    \n",
    "    lci_cond = lci_dat['conductivity'][point_ind_lci].data\n",
    "    lci_depth_top = lci_dat['layer_top_depth'][point_ind_lci].data\n",
    "    \n",
    "    lci_doi = lci_dat['depth_of_investigation'][point_ind_lci].data\n",
    "    \n",
    "    misfit = rj_dat['misfit'][point_ind_rj].data\n",
    "    sample_no = rj_dat['rj_sample_number'][:].data\n",
    "    \n",
    "    burnin = rj_dat[\"nburnin\"][point_ind_rj].data\n",
    "    nsamples = rj_dat['nsamples'][point_ind_rj].data\n",
    "    nchains = rj_dat['nchains'][point_ind_rj].data\n",
    "    \n",
    "    line_ind = rj_dat['line_index'][point_ind_rj].data\n",
    "    line = int(rj_dat['line'][line_ind].data)\n",
    "    \n",
    "    return {'conductivity_pdf': cond_pdf, \"change_point_pdf\": cp_pdf, \"conductivity_extent\": extent,\n",
    "           'cond_p10': p10, 'cond_p50': p50, 'cond_p90': p90, 'cond_mean': mean, 'depth_cells': depth_cells,\n",
    "           'nlayer_bins': laybins, 'nlayer_prob': lay_prob, 'nsamples': nsamples, 'ndata': rj_dat['n_data'][:].data,\n",
    "           \"nchains\": nchains, 'burnin': burnin, 'misfit': misfit, 'sample_no': sample_no, 'cond_cells': cond_cells, 'lci_cond': lci_cond,\n",
    "           'lci_depth_top': lci_depth_top, 'lci_doi': lci_doi, 'line': line}\n",
    "    \n",
    "def DR_plot(D, outfile = None):\n",
    "    fig = plt.figure(figsize = (12,10))\n",
    "\n",
    "    # These are for interactive widget mode\n",
    "    fig.canvas.layout.width = '6in'\n",
    "    fig.canvas.layout.height= '5in'\n",
    "\n",
    "    ax1 = fig.add_axes([0.05, 0.35, 0.35, 0.62])\n",
    "    ax2 = fig.add_axes([0.45, 0.35, 0.2, 0.62])\n",
    "    ax3 = fig.add_axes([0.70, 0.52, 0.2, 0.2])\n",
    "    ax4 = fig.add_axes([0.72, 0.32, 0.16, 0.16])\n",
    "    ax5 = fig.add_axes([0.1, 0.18, 0.76, 0.05])\n",
    "    ax6 = fig.add_axes([0.1, 0.05, 0.76, 0.13])\n",
    "    ax7 = fig.add_axes([0.70, 0.78, 0.2, 0.2])\n",
    "    cbar_ax1 = fig.add_axes([0.05, 0.29, 0.35, 0.01])\n",
    "    cbar_ax2 = fig.add_axes([0.88, 0.05, 0.01, 0.2])\n",
    "    \n",
    "    panel_kwargs = [{'title': '',\n",
    "                      'color': 'black',\n",
    "                      'ylabel': 'data \\n residual',\n",
    "                      'legend': False},\n",
    "                     {'title': 'LCI conductivity',\n",
    "                      'max_depth': 450.,\n",
    "                      'shade_doi': True,\n",
    "                      'colourbar': True,\n",
    "                      'colourbar_label': 'Conductivity (S/m)',\n",
    "                      'log_plot': True,\n",
    "                      'vmin': 0.001,\n",
    "                      'vmax': 2.,\n",
    "                      'cmap': 'jet',\n",
    "                      'ylabel': 'elevation \\n (mAHD)',\n",
    "                      'vertical_exaggeration': 1.0}]\n",
    "\n",
    "\n",
    "    # Plot probability map\n",
    "    \n",
    "    im = ax1.imshow(D['conductivity_pdf'], extent = D['conductivity_extent'],\n",
    "                    aspect = 'auto', cmap = 'rainbow')\n",
    "    \n",
    "    #  PLot the median, and percentile plots\n",
    "    ax1.plot(np.log10(D['cond_p10']), D['depth_cells'], c = 'k',linestyle='dashed', label = 'p10')\n",
    "    ax1.plot(np.log10(D['cond_p90']), D['depth_cells'], c = 'k',linestyle='dashed', label = 'p90')\n",
    "    ax1.plot(np.log10(D['cond_p50']), D['depth_cells'], c = 'k',label = 'p50')\n",
    "    ax1.plot(np.log10(D['cond_mean']), D['depth_cells'], c = 'grey',label = 'mean')\n",
    "    \n",
    "    ax1.set_xticklabels([round(10 ** float(x), 4) for x in ax1.get_xticks()])\n",
    "\n",
    "    # for lci layered model we do some processing\n",
    "    lci_expanded = np.zeros(shape=2 * len(D['lci_cond']) + 1,\n",
    "                                 dtype=np.float)\n",
    "\n",
    "    lci_expanded[1:] = np.repeat(D['lci_cond'], 2)\n",
    "\n",
    "    depth_expanded = (np.max(D['lci_depth_top']) + 10) * np.ones(shape=len(lci_expanded),\n",
    "                                                            dtype=np.float)\n",
    "\n",
    "    depth_expanded[:-1] = np.repeat(D['lci_depth_top'], 2)\n",
    "\n",
    "    ax1.plot(np.log10(lci_expanded), depth_expanded, c = 'pink',\n",
    "             linestyle = 'dashed', label = 'lci')\n",
    "    ax1.plot(ax1.get_xlim(), [D['lci_doi'], D['lci_doi']], c = 'yellow',\n",
    "             label = 'LCI doi')\n",
    "    ax1.set_title('rj-MCMC probability map')\n",
    "    ax1.set_ylabel('depth (mBGL)')\n",
    "    ax1.set_xlabel('Conductivity (S/m)')\n",
    "    ax1.grid(which = 'both')\n",
    "    ax1.set_xlim(D['conductivity_extent'][0], D['conductivity_extent'][1] )\n",
    "    \n",
    "    ax1.set_ylim(D['conductivity_extent'][2], D['conductivity_extent'][3])#100.,0)#\n",
    "    \n",
    "    \n",
    "    ax1.plot(ax1.get_xlim(), [row['topJind_depth'], row['topJind_depth']],\n",
    "            c = 'green', linewidth = 2, label = 'top Jinduckin - BOM')\n",
    "    ax1.legend(loc = 3)\n",
    "    ax2.plot(D['change_point_pdf'], D['depth_cells'], label = 'P(change point)')\n",
    "    ax2.set_ylim(ax2.get_ylim()[::-1])\n",
    "    ax2.set_yticks(np.arange(0, 500, 20.))\n",
    "    ax2.set_title('change point probability')\n",
    "    ax2.set_ylim(D['conductivity_extent'][2], D['conductivity_extent'][3])#(100.,0)\n",
    "    ax2.plot(ax2.get_xlim(), [row['topJind_depth'], row['topJind_depth']],\n",
    "            c = 'green', linewidth = 2, label = 'top Jinduckin - BOM')\n",
    "    ax2.legend()\n",
    "    ax2.grid(which = 'both')\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    ax3.imshow(contact_elev, \n",
    "               extent = [contact_dataset.bounds[0], contact_dataset.bounds[2],\n",
    "                         contact_dataset.bounds[1], contact_dataset.bounds[3]],\n",
    "              cmap= 'viridis')#, vmin = -2., vmax = 2.)\n",
    "    #ax3.set_xlim(D['easting'] - 10000., D['easting'] + 10000.)\n",
    "    #ax3.set_ylim(D['northing'] - 10000., D['northing'] + 10000.)\n",
    "    ax3.plot(D['easting'],D['northing'], 'x', c = 'r')\n",
    "    ax3.set_title('Oolloo-Jinduckin contact', fontsize=10)\n",
    "    #ax3.set_title(\"Top Oolloo\")\n",
    "    ax3.tick_params(axis='both', which='major', labelsize=8)\n",
    "    ax3.tick_params(axis='both', which='minor', labelsize=8)\n",
    "    # Ax3 will be our location\n",
    "    sample = D['sample_no'][:]\n",
    "    \n",
    "    # Add the misfit\n",
    "    for i in range(D['misfit'].shape[0]):\n",
    "       \n",
    "        misfits = D['misfit'][i]\n",
    "        ax4.plot(sample, misfits/D['ndata'])\n",
    "\n",
    "    ax4.plot([1, D['nsamples']], [1,1], 'k')\n",
    "    ax4.plot([D['burnin'], D['burnin']],[0.1,1e4], 'k')\n",
    "    ax4.set_xlim([1, D['nsamples']])\n",
    "    ax4.set_ylim(0.1, 1e4)\n",
    "\n",
    "    ax4.set_xscale('log')\n",
    "    ax4.set_yscale('log')\n",
    "\n",
    "    ax4.set_xlabel(\"sample #\")\n",
    "    ax4.set_ylabel(\"Normalised misfit\")\n",
    "    \n",
    "    # conductivity plot\n",
    "    \n",
    "    ax7.imshow(np.log10(cond[9]), extent = [cond_dataset.bounds[0],\n",
    "                                  cond_dataset.bounds[2],\n",
    "                                  cond_dataset.bounds[1], \n",
    "                                  cond_dataset.bounds[3]],\n",
    "              cmap = 'jet',\n",
    "              vmin = np.log10(panel_kwargs[1]['vmin']*1000.),\n",
    "              vmax = np.log10(panel_kwargs[1]['vmax']*1000.))\n",
    "    \n",
    "    ax7.set_xlim(D['easting'] - 10000., D['easting'] + 10000.)\n",
    "    ax7.set_ylim(D['northing'] - 10000., D['northing'] + 10000.)\n",
    "    ax7.plot(D['easting'],D['northing'],  'x', c = 'k')\n",
    "    \n",
    "    p1 = [gridded_vars[line]['easting'][0], gridded_vars[line]['easting'][-1]]\n",
    "    p2 = [gridded_vars[line]['northing'][0], gridded_vars[line]['northing'][-1]]\n",
    "    ax7.plot(p1, p2, 'k', linewidth = 0.5)\n",
    "    ax7.set_title('LCI depth slice 61.8-71.6 mBGL', fontsize=10)\n",
    "    ax7.tick_params(axis='both', which='major', labelsize=8)\n",
    "    ax7.tick_params(axis='both', which='minor', labelsize=8)\n",
    "    cb1 = fig.colorbar(im, cax=cbar_ax1, orientation='horizontal')\n",
    "    cb1.set_label('probabilitiy', fontsize=10)\n",
    "\n",
    "    res1 = plot_utils.plot_single_line(ax5, gridded_vars[line],\n",
    "                                       'data_residual', panel_kwargs[0])\n",
    "\n",
    "    ax5.set_title('LCI conductivity section - ' + str(line))\n",
    "\n",
    "    im2 = plot_utils.plot_grid(ax6, gridded_vars[line], 'conductivity',\n",
    "                               panel_kwargs[1])\n",
    "    \n",
    "    # PLot jinduckin elevation onto section\n",
    "    ax6.plot(gridded_vars[line]['grid_distances'],\n",
    "            gridded_vars[line]['topJind_elev'], c = 'k',\n",
    "            linestyle = 'dashed')\n",
    "    \n",
    "    # Add colorbars\n",
    "\n",
    "    ax6.plot([dist, dist], [-500, 500], 'pink')\n",
    "    \n",
    "        \n",
    "    cb2 = fig.colorbar(im2, cax=cbar_ax2, orientation='vertical')\n",
    "    \n",
    "    cb2.ax.set_yticklabels([round(10 ** x, 4) for x in cb2.get_ticks()])\n",
    "    cb2.set_label('conductivity (S/m)', fontsize=10)\n",
    "    \n",
    "    ax5.set_xlim(dist,# - 5000.,\n",
    "                 dist)# + 5000.)\n",
    "    ax6.set_xlim(dist,# - 5000., \n",
    "                 dist)# + 5000.)\n",
    "\n",
    "    \n",
    "    \n",
    "    return fig   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255.01165511415832"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "\n",
    "df_ss.at[ind, 'topJind_interp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PCUser\\Anaconda3\\envs\\hydrogeol_utils\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c9ae1a6265e4bde99a23ef337594a27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PCUser\\Anaconda3\\envs\\hydrogeol_utils\\lib\\site-packages\\ipykernel_launcher.py:116: RuntimeWarning: divide by zero encountered in log10\n",
      "C:\\Users\\PCUser\\Anaconda3\\envs\\hydrogeol_utils\\lib\\site-packages\\ipykernel_launcher.py:178: RuntimeWarning: invalid value encountered in log10\n",
      "C:\\Users\\PCUser\\Anaconda3\\envs\\hydrogeol_utils\\lib\\site-packages\\ipykernel_launcher.py:223: UserWarning: Attempting to set identical left == right == 10670.0 results in singular transformations; automatically expanding.\n",
      "C:\\Users\\PCUser\\Anaconda3\\envs\\hydrogeol_utils\\lib\\site-packages\\ipykernel_launcher.py:225: UserWarning: Attempting to set identical left == right == 10670.0 results in singular transformations; automatically expanding.\n"
     ]
    }
   ],
   "source": [
    "# Define some coordinates to investigate\n",
    "unid = 51\n",
    "\n",
    "cond_gen = gen(df_ss[df['uniqueid '] == unid])\n",
    "\n",
    "\n",
    "ind, row = next(cond_gen)\n",
    "\n",
    "point_ind_lci = row['point_ind_lci']\n",
    "\n",
    "point_ind_rj = row['point_ind_rj']\n",
    "\n",
    "# Get the nearest lci point\n",
    "\n",
    "easting, northing = row['easting '], row['northing ']\n",
    "\n",
    "\n",
    "plt.close('all')\n",
    "\n",
    "D = extract_data()\n",
    "\n",
    "D['easting'], D['northing'] = easting, northing\n",
    "\n",
    "line = row['line ']\n",
    "\n",
    "# Find distance along the lci section\n",
    "dist = xy_2_var(gridded_vars[line],\n",
    "                 np.array([[easting, northing]]),\n",
    "                         'grid_distances')\n",
    "\n",
    "\n",
    "point_ind_lci= dist\n",
    "\n",
    "fig = DR_plot(D)\n",
    "#plt.savefig(r\"C:\\Users\\PCUser\\Desktop\\NSC_data\\DR_interp\\rjplots\\\\Florina_\" + row['BORE_NO'] + \".png\", dpi = 150)\n",
    "cid=  fig.canvas.mpl_connect('button_press_event', onclick)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we extract some AEM data for further inversion\n",
    "\n",
    "# bring in a shapefile as a geometry\n",
    "\n",
    "infile = r\"C:\\Users\\PCUser\\Desktop\\NSC_data\\data\\vector\\DalyRiver\\DalyGeology_August2018.shp\"\n",
    "\n",
    "from osgeo import ogr\n",
    "file = ogr.Open(infile)\n",
    "shape = file.GetLayer(0)\n",
    "#first feature of the shapefile\n",
    "feature = shape.GetFeature(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "shapefile = json.loads(feature.ExportToJson())\n",
    "\n",
    "Oolloo_extent = Polygon(shapefile['geometry']['coordinates'][0])\n",
    "\n",
    "from functools import partial\n",
    "import pyproj\n",
    "from shapely.ops import transform\n",
    "\n",
    "project = partial(\n",
    "    pyproj.transform,\n",
    "    pyproj.Proj(init='epsg:4283'), # source coordinate system\n",
    "    pyproj.Proj(init='epsg:28352')) # destination coordinate system\n",
    "\n",
    "Oolloo_extent = transform(project, Oolloo_extent)  # apply projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174148"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bring in the inversion ready data\n",
    "\n",
    "infile = r\"C:\\temp\\DR_inversion_ready.dat\"\n",
    "\n",
    "gdf = aseg_gdf2.read(infile).df()\n",
    "\n",
    "gdf = gdf[gdf['line '] > 102800]\n",
    "\n",
    "gdf = gdf[gdf['line '] < 110302]\n",
    "\n",
    "gdf = gdf[~gdf['line '].isin([105601, 105602, 106301, 109601, 109701, 110203,\n",
    "                            110301, 109204, 109203])]\n",
    "\n",
    "len(gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterate through an get the indices of those that fall within the Oolloo\n",
    "\n",
    "idx = []\n",
    "\n",
    "for index, row in gdf.iterrows():\n",
    "    coords = row[['easting ', 'northing']].values\n",
    "    \n",
    "    if Oolloo_extent.contains(Point(coords)):\n",
    "        idx.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(infile, 'r' ) as inf:\n",
    "    with open(infile.replace('.dat', '_Oolloo_ss.dat'), 'w') as outf:\n",
    "        for i, line in enumerate(inf):\n",
    "            if i in idx:\n",
    "                outf.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 1304 20170824 20170824.01  109803  1987689.50 835282.19 8332937.00    46.4   229.78   319.81  -0.68  -3.89   0.00 -13.20  -0.02  -2.90   1.303772E+03   6.575904E+02   3.666201E+02   2.966533E+02   2.163259E+02   1.643671E+02   1.213579E+02   8.753586E+01   6.320110E+01   4.364177E+01   2.932486E+01   2.019422E+01   1.243360E+01   7.912390E+00   4.841930E+00   2.799800E+00   1.637730E+00   9.954300E-01   2.078585E+01   1.751578E+01   1.445528E+01   1.158486E+01   9.019670E+00   6.797270E+00   4.939920E+00   3.482580E+00   2.357370E+00   1.526070E+00   9.537500E-01   5.677100E-01   3.246600E-01   1.810300E-01   9.784000E-02   4.896000E-02   2.466000E-02   1.280000E-02   6.360000E-03   2.520000E-03   9.700000E-04   3.900000E-04  -1.500000E-04   4.008152E+01   2.156813E+01   1.259915E+01   9.489408E+00   7.013184E+00   5.332332E+00   3.967027E+00   2.920324E+00   2.161076E+00   1.551778E+00   1.063017E+00   7.623128E-01   5.074975E-01   3.602310E-01   2.744778E-01   2.102015E-01   1.676278E-01   1.525650E-01   6.285515E-01   5.271253E-01   4.343324E-01   3.479026E-01   2.708161E-01   2.041626E-01   1.484514E-01   1.046791E-01   7.092615E-02   4.597633E-02   2.879536E-02   1.718261E-02   9.866686E-03   5.598834E-03   3.162904E-03   1.700249E-03   1.006038E-03   6.687340E-04   5.526055E-04   4.708387E-04   4.092559E-04   3.729980E-04   3.453754E-04'"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i in idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx[66] in idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
